{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0003b0bc",
   "metadata": {},
   "source": [
    "## 16. 다음에 볼 영화 예측하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ed8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 설명(README)를 읽어 봅니다. \n",
    "import os\n",
    "f = open(os.getenv('HOME')+'/aiffel/yoochoose/data/dataset-README.txt', 'r')\n",
    "while True:\n",
    "    line = f.readline()\n",
    "    if not line: break\n",
    "    print(line)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff815caa",
   "metadata": {},
   "source": [
    "또한 E-Commerce 데이터의 경우 다음과 같은 특징을 갖는다고 합니다.\n",
    "1. 비로그인 상태로 탐색하는 유저가 많습니다.\n",
    "2. 로그인 상태로 탐색한다고 할지라도 접속할 때마다 탐색하는 의도가 뚜렷하게 다릅니다.\n",
    "\n",
    "즉, 마우스를 사야겠다고 마음먹고 탐색한 이력이 칫솔을 사야겠다 생각하고 탐색하는 경우에 도움이 되지 않습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af89935f",
   "metadata": {},
   "source": [
    "### 16-2. Data Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b9793e",
   "metadata": {},
   "source": [
    "#### 2.1 Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a20056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72775b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(os.getenv('HOME')+'/aiffel/yoochoose/data') \n",
    "train_path = data_path / 'yoochoose-clicks.dat'\n",
    "train_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45c65d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path: Path, nrows=None):\n",
    "    data = pd.read_csv(data_path, sep=',', header=None, usecols=[0, 1, 2],\n",
    "                       parse_dates=[1], dtype={0: np.int32, 2: np.int32}, nrows=nrows)\n",
    "    data.columns = ['SessionId', 'Time', 'ItemId']\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437f2ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시간이 좀 걸릴 수 있습니다. 메모리도 10GB 가까이 소요될 수 있으니 메모리 상태에 주의해 주세요.  \n",
    "\n",
    "data = load_data(train_path, None)\n",
    "data.sort_values(['SessionId', 'Time'], inplace=True)  # data를 id와 시간 순서로 정렬해줍니다.\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce0c7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['SessionId'].nunique(), data['ItemId'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438fdba9",
   "metadata": {},
   "source": [
    "세션의 숫자가 약 900만 개, 아이템 숫자는 약 5만 개가 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac4181a",
   "metadata": {},
   "source": [
    "#### 2.2 Session Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2596286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_length = data.groupby('SessionId').size()\n",
    "session_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6010da36",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_length.median(), session_length.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bbdc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_length.min(), session_length.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb9f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_length.quantile(0.999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4002d",
   "metadata": {},
   "source": [
    "99.9% 세션은 길이가 41이하입니다.\n",
    "길이가 200인 세션은 뭔가 이상합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f964db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_session = session_length[session_length==200].index[0]\n",
    "data[data['SessionId']==long_session]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa6a194",
   "metadata": {},
   "source": [
    "세션 길이 기준 하위 99.9%까지의 분포 누적합을 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58826b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "length_count = session_length.groupby(session_length).size()\n",
    "length_percent_cumsum = length_count.cumsum() / length_count.sum()\n",
    "length_percent_cumsum_999 = length_percent_cumsum[length_percent_cumsum < 0.999]\n",
    "\n",
    "length_percent_cumsum_999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39318330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.bar(x=length_percent_cumsum_999.index,\n",
    "        height=length_percent_cumsum_999, color='red')\n",
    "plt.xticks(length_percent_cumsum_999.index)\n",
    "plt.yticks(np.arange(0, 1.01, 0.05))\n",
    "plt.title('Cumsum Percentage Until 0.999', size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb2ffc",
   "metadata": {},
   "source": [
    "#### 2.3 Session Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a4728",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldest, latest = data['Time'].min(), data['Time'].max()\n",
    "print(oldest) \n",
    "print(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a554b120",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(latest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d956d711",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_ago = latest - dt.timedelta(30)     # 최종 날짜로부터 30일 이전 날짜를 구한다.  \n",
    "data = data[data['Time'] > month_ago]   # 방금 구한 날짜 이후의 데이터만 모은다. \n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9624921",
   "metadata": {},
   "source": [
    "#### 2.4 Data Cleansing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d3e412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# short_session을 제거한 다음 unpopular item을 제거하면 다시 길이가 1인 session이 생길 수 있습니다.\n",
    "# 이를 위해 반복문을 통해 지속적으로 제거 합니다.\n",
    "def cleanse_recursive(data: pd.DataFrame, shortest, least_click) -> pd.DataFrame:\n",
    "    while True:\n",
    "        before_len = len(data)\n",
    "        data = cleanse_short_session(data, shortest)\n",
    "        data = cleanse_unpopular_item(data, least_click)\n",
    "        after_len = len(data)\n",
    "        if before_len == after_len:\n",
    "            break\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanse_short_session(data: pd.DataFrame, shortest):\n",
    "    session_len = data.groupby('SessionId').size()\n",
    "    session_use = session_len[session_len >= shortest].index\n",
    "    data = data[data['SessionId'].isin(session_use)]\n",
    "    return data\n",
    "\n",
    "\n",
    "def cleanse_unpopular_item(data: pd.DataFrame, least_click):\n",
    "    item_popular = data.groupby('ItemId').size()\n",
    "    item_use = item_popular[item_popular >= least_click].index\n",
    "    data = data[data['ItemId'].isin(item_use)]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0291e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleanse_recursive(data, shortest=2, least_click=5)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c02e7d",
   "metadata": {},
   "source": [
    "#### 2.5 Train / Valid / Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb48319",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = data_path / 'yoochoose-test.dat'\n",
    "test= load_data(test_path)\n",
    "test['Time'].min(), test['Time'].max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205110c9",
   "metadata": {},
   "source": [
    "가장 마지막 1일 기간 동안을 Test로, 2일 전부터 1일 전 까지를 valid set으로 나누겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a370bdc3",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/split.max-800x600.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb2ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_date(data: pd.DataFrame, n_days: int):\n",
    "    final_time = data['Time'].max()\n",
    "    session_last_time = data.groupby('SessionId')['Time'].max()\n",
    "    session_in_train = session_last_time[session_last_time < final_time - dt.timedelta(n_days)].index\n",
    "    session_in_test = session_last_time[session_last_time >= final_time - dt.timedelta(n_days)].index\n",
    "\n",
    "    before_date = data[data['SessionId'].isin(session_in_train)]\n",
    "    after_date = data[data['SessionId'].isin(session_in_test)]\n",
    "    after_date = after_date[after_date['ItemId'].isin(before_date['ItemId'])]\n",
    "    return before_date, after_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd48e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr, test = split_by_date(data, n_days=1)\n",
    "tr, val = split_by_date(tr, n_days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2842744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data에 대한 정보를 살펴봅니다.\n",
    "def stats_info(data: pd.DataFrame, status: str):\n",
    "    print(f'* {status} Set Stats Info\\n'\n",
    "          f'\\t Events: {len(data)}\\n'\n",
    "          f'\\t Sessions: {data[\"SessionId\"].nunique()}\\n'\n",
    "          f'\\t Items: {data[\"ItemId\"].nunique()}\\n'\n",
    "          f'\\t First Time : {data[\"Time\"].min()}\\n'\n",
    "          f'\\t Last Time : {data[\"Time\"].max()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab8e6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_info(tr, 'train')\n",
    "stats_info(val, 'valid')\n",
    "stats_info(test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b899aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train set에 없는 아이템이 val, test기간에 생길 수 있으므로 train data를 기준으로 인덱싱합니다.\n",
    "id2idx = {item_id : index for index, item_id in enumerate(tr['ItemId'].unique())}\n",
    "\n",
    "def indexing(df, id2idx):\n",
    "    df['item_idx'] = df['ItemId'].map(lambda x: id2idx.get(x, -1))  # id2idx에 없는 아이템은 모르는 값(-1) 처리 해줍니다.\n",
    "    return df\n",
    "\n",
    "tr = indexing(tr, id2idx)\n",
    "val = indexing(val, id2idx)\n",
    "test = indexing(test, id2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3ca120",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = data_path / 'processed'\n",
    "save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "tr.to_pickle(save_path / 'train.pkl')\n",
    "val.to_pickle(save_path / 'valid.pkl')\n",
    "test.to_pickle(save_path / 'test.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c79e39",
   "metadata": {},
   "source": [
    "### 16-3. 논문소개(GRU4REC)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5bd56c",
   "metadata": {},
   "source": [
    "이번 자료에서 사용할 모델은 2016년 ICLR에 공개된 SESSION-BASED RECOMMENDATIONS WITH RECURRENT NEURAL NETWORKS 입니다.  \n",
    "https://arxiv.org/pdf/1511.06939v4.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439a6d34",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/model.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f918b4e5",
   "metadata": {},
   "source": [
    "Session-Parallel Mini-Batches :"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8be7294",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/input1.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f3fbfc5",
   "metadata": {},
   "source": [
    " Mini-Batch의 shape은 (3, 1, 1)이 되고 RNN cell의 state가 1개로만 이루어집"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f652c7e1",
   "metadata": {},
   "source": [
    "![](https://d3s0tskafalll9.cloudfront.net/media/images/input2.max-800x600.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0c7738",
   "metadata": {},
   "source": [
    "SAMPLING ON THE OUTPUT -  인기도를 고려하여 Sampling. 코드에 구현은 하지않음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b1c813",
   "metadata": {},
   "source": [
    "Ranking Loss 대신에 코드에서는 Classification Task로 보고 Cross-Entropy Loss를 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eb1e3c",
   "metadata": {},
   "source": [
    "### 16-4. Data Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beec380",
   "metadata": {},
   "source": [
    "Session-Parallel Mini-Batch 를 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5b93c3",
   "metadata": {},
   "source": [
    "#### 4.1 SessionDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04734cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionDataset:\n",
    "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n",
    "\n",
    "    def __init__(self, data):\n",
    "        self.df = data\n",
    "        self.click_offsets = self.get_click_offsets()\n",
    "        self.session_idx = np.arange(self.df['SessionId'].nunique())  # indexing to SessionId\n",
    "\n",
    "    def get_click_offsets(self):\n",
    "        \"\"\"\n",
    "        Return the indexes of the first click of each session IDs,\n",
    "        \"\"\"\n",
    "        offsets = np.zeros(self.df['SessionId'].nunique() + 1, dtype=np.int32)\n",
    "        offsets[1:] = self.df.groupby('SessionId').size().cumsum()\n",
    "        return offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4129cfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset = SessionDataset(tr)\n",
    "tr_dataset.df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcb11b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset.click_offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57551c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_dataset.session_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cab04e",
   "metadata": {},
   "source": [
    "#### 4.2 SessionDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36f26fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SessionDataLoader:\n",
    "    \"\"\"Credit to yhs-968/pyGRU4REC.\"\"\"\n",
    "\n",
    "    def __init__(self, dataset: SessionDataset, batch_size=50):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\" Returns the iterator for producing session-parallel training mini-batches.\n",
    "        Yields:\n",
    "            input (B,):  Item indices that will be encoded as one-hot vectors later.\n",
    "            target (B,): a Variable that stores the target item indices\n",
    "            masks: Numpy array indicating the positions of the sessions to be terminated\n",
    "        \"\"\"\n",
    "\n",
    "        start, end, mask, last_session, finished = self.initialize()  # initialize 메소드에서 확인해주세요.\n",
    "        \"\"\"\n",
    "        start : Index Where Session Start\n",
    "        end : Index Where Session End\n",
    "        mask : indicator for the sessions to be terminated\n",
    "        \"\"\"\n",
    "\n",
    "        while not finished:\n",
    "            min_len = (end - start).min() - 1  # Shortest Length Among Sessions\n",
    "            for i in range(min_len):\n",
    "                # Build inputs & targets\n",
    "                inp = self.dataset.df['item_idx'].values[start + i]\n",
    "                target = self.dataset.df['item_idx'].values[start + i + 1]\n",
    "                yield inp, target, mask\n",
    "\n",
    "            start, end, mask, last_session, finished = self.update_status(start, end, min_len, last_session, finished)\n",
    "\n",
    "    def initialize(self):\n",
    "        first_iters = np.arange(self.batch_size)    # 첫 배치에 사용할 세션 Index를 가져옵니다.\n",
    "        last_session = self.batch_size - 1    # 마지막으로 다루고 있는 세션 Index를 저장해둡니다.\n",
    "        start = self.dataset.click_offsets[self.dataset.session_idx[first_iters]]       # data 상에서 session이 시작된 위치를 가져옵니다.\n",
    "        end = self.dataset.click_offsets[self.dataset.session_idx[first_iters] + 1]  # session이 끝난 위치 바로 다음 위치를 가져옵니다.\n",
    "        mask = np.array([])   # session의 모든 아이템을 다 돌은 경우 mask에 추가해줄 것입니다.\n",
    "        finished = False         # data를 전부 돌았는지 기록하기 위한 변수입니다.\n",
    "        return start, end, mask, last_session, finished\n",
    "\n",
    "    def update_status(self, start: np.ndarray, end: np.ndarray, min_len: int, last_session: int, finished: bool):  \n",
    "        # 다음 배치 데이터를 생성하기 위해 상태를 update합니다.\n",
    "        \n",
    "        start += min_len   # __iter__에서 min_len 만큼 for문을 돌았으므로 start를 min_len 만큼 더해줍니다.\n",
    "        mask = np.arange(self.batch_size)[(end - start) == 1]  \n",
    "        # end는 다음 세션이 시작되는 위치인데 start와 한 칸 차이난다는 것은 session이 끝났다는 뜻입니다. mask에 기록해줍니다.\n",
    "\n",
    "        for i, idx in enumerate(mask, start=1):  # mask에 추가된 세션 개수만큼 새로운 세션을 돌것입니다.\n",
    "            new_session = last_session + i  \n",
    "            if new_session > self.dataset.session_idx[-1]:  # 만약 새로운 세션이 마지막 세션 index보다 크다면 모든 학습데이터를 돈 것입니다.\n",
    "                finished = True\n",
    "                break\n",
    "            # update the next starting/ending point\n",
    "            start[idx] = self.dataset.click_offsets[self.dataset.session_idx[new_session]]     # 종료된 세션 대신 새로운 세션의 시작점을 기록합니다.\n",
    "            end[idx] = self.dataset.click_offsets[self.dataset.session_idx[new_session] + 1]\n",
    "\n",
    "        last_session += len(mask)  # 마지막 세션의 위치를 기록해둡니다.\n",
    "        return start, end, mask, last_session, finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f0f488",
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_data_loader = SessionDataLoader(tr_dataset, batch_size=4)\n",
    "tr_dataset.df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c12d134",
   "metadata": {},
   "outputs": [],
   "source": [
    "iter_ex = iter(tr_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da360ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels, mask =  next(iter_ex)\n",
    "print(f'Model Input Item Idx are : {inputs}')\n",
    "print(f'Label Item Idx are : {\"\":5} {labels}')\n",
    "print(f'Previous Masked Input Idx are {mask}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a61cc8",
   "metadata": {},
   "source": [
    "### 16-5. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f0adc8",
   "metadata": {},
   "source": [
    "#### 5.1 Evaluation Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac16b5c",
   "metadata": {},
   "source": [
    "Session-Based Recommendation Task에서는 모델이 k개의 아이템을 제시했을 때, 유저가 클릭/ 구매한 n개의 아이템이 많아야 좋습니다.\n",
    "이 때문에 recall의 개념을 확장한 recall@k 지표, precision의 개념을 확장한 Mean Average Precision@k 지표 등을 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02b3d44",
   "metadata": {},
   "source": [
    " 순서에 민감한 지표인 MRR, NDCG 같은 지표도 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb875ac",
   "metadata": {},
   "source": [
    "이번 자료에서는 MRR과 Recall@k를 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c1f503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mrr_k(pred, truth: int, k: int):\n",
    "    indexing = np.where(pred[:k] == truth)[0]\n",
    "    if len(indexing) > 0:\n",
    "        return 1 / (indexing[0] + 1)\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def recall_k(pred, truth: int, k: int) -> int:\n",
    "    answer = truth in pred[:k]\n",
    "    return int(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4e6e27",
   "metadata": {},
   "source": [
    "#### 5.2 Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2dbcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, GRU\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefe10d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(args):\n",
    "    inputs = Input(batch_shape=(args.batch_size, 1, args.num_items))\n",
    "    gru, _ = GRU(args.hsz, stateful=True, return_state=True, name='GRU')(inputs)\n",
    "    dropout = Dropout(args.drop_rate)(gru)\n",
    "    predictions = Dense(args.num_items, activation='softmax')(dropout)\n",
    "    model = Model(inputs=inputs, outputs=[predictions])\n",
    "    model.compile(loss=categorical_crossentropy, optimizer=Adam(args.lr), metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e5b82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, tr, val, test, batch_size, hsz, drop_rate, lr, epochs, k):\n",
    "        self.tr = tr\n",
    "        self.val = val\n",
    "        self.test = test\n",
    "        self.num_items = tr['ItemId'].nunique()\n",
    "        self.num_sessions = tr['SessionId'].nunique()\n",
    "        self.batch_size = batch_size\n",
    "        self.hsz = hsz\n",
    "        self.drop_rate = drop_rate\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.k = k\n",
    "\n",
    "args = Args(tr, val, test, batch_size=2048, hsz=50, drop_rate=0.1, lr=0.001, epochs=3, k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2469fa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066806bf",
   "metadata": {},
   "source": [
    "#### 5.3 Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be709948",
   "metadata": {},
   "source": [
    "모델 학습에 걸리는 시간은 epoch당 30분이 넘어갑니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63526be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train 셋으로 학습하면서 valid 셋으로 검증합니다.\n",
    "def train_model(model, args):\n",
    "    train_dataset = SessionDataset(args.tr)\n",
    "    train_loader = SessionDataLoader(train_dataset, batch_size=args.batch_size)\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        total_step = len(args.tr) - args.tr['SessionId'].nunique()\n",
    "        tr_loader = tqdm(train_loader, total=total_step // args.batch_size, desc='Train', mininterval=1)\n",
    "        for feat, target, mask in tr_loader:\n",
    "            reset_hidden_states(model, mask)  # 종료된 session은 hidden_state를 초기화합니다. 아래 메서드에서 확인해주세요.\n",
    "\n",
    "            input_ohe = to_categorical(feat, num_classes=args.num_items)\n",
    "            input_ohe = np.expand_dims(input_ohe, axis=1)\n",
    "            target_ohe = to_categorical(target, num_classes=args.num_items)\n",
    "\n",
    "            result = model.train_on_batch(input_ohe, target_ohe)\n",
    "            tr_loader.set_postfix(train_loss=result[0], accuracy = result[1])\n",
    "\n",
    "        val_recall, val_mrr = get_metrics(args.val, model, args, args.k)  # valid set에 대해 검증합니다.\n",
    "\n",
    "        print(f\"\\t - Recall@{args.k} epoch {epoch}: {val_recall:3f}\")\n",
    "        print(f\"\\t - MRR@{args.k}    epoch {epoch}: {val_mrr:3f}\\n\")\n",
    "\n",
    "\n",
    "def reset_hidden_states(model, mask):\n",
    "    gru_layer = model.get_layer(name='GRU')  # model에서 gru layer를 가져옵니다.\n",
    "    hidden_states = gru_layer.states[0].numpy()  # gru_layer의 parameter를 가져옵니다.\n",
    "    for elt in mask:  # mask된 인덱스 즉, 종료된 세션의 인덱스를 돌면서\n",
    "        hidden_states[elt, :] = 0  # parameter를 초기화 합니다.\n",
    "    gru_layer.reset_states(states=hidden_states)\n",
    "\n",
    "\n",
    "def get_metrics(data, model, args, k: int):  # valid셋과 test셋을 평가하는 코드입니다. \n",
    "                                             # train과 거의 같지만 mrr, recall을 구하는 라인이 있습니다.\n",
    "    dataset = SessionDataset(data)\n",
    "    loader = SessionDataLoader(dataset, batch_size=args.batch_size)\n",
    "    recall_list, mrr_list = [], []\n",
    "\n",
    "    total_step = len(data) - data['SessionId'].nunique()\n",
    "    for inputs, label, mask in tqdm(loader, total=total_step // args.batch_size, desc='Evaluation', mininterval=1):\n",
    "        reset_hidden_states(model, mask)\n",
    "        input_ohe = to_categorical(inputs, num_classes=args.num_items)\n",
    "        input_ohe = np.expand_dims(input_ohe, axis=1)\n",
    "\n",
    "        pred = model.predict(input_ohe, batch_size=args.batch_size)\n",
    "        pred_arg = tf.argsort(pred, direction='DESCENDING')  # softmax 값이 큰 순서대로 sorting 합니다.\n",
    "\n",
    "        length = len(inputs)\n",
    "        recall_list.extend([recall_k(pred_arg[i], label[i], k) for i in range(length)])\n",
    "        mrr_list.extend([mrr_k(pred_arg[i], label[i], k) for i in range(length)])\n",
    "\n",
    "    recall, mrr = np.mean(recall_list), np.mean(mrr_list)\n",
    "    return recall, mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d85d802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 시간이 다소 오래 소요됩니다. 아래 주석을 풀지 마세요.\n",
    "# train_model(model, args)\n",
    "\n",
    "# 학습된 모델을 불러옵니다.\n",
    "model = tf.keras.models.load_model(data_path / 'trained_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200e2c95",
   "metadata": {},
   "source": [
    "#### 5.4 Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526a2aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, args, test):\n",
    "    test_recall, test_mrr = get_metrics(test, model, args, 20)\n",
    "    print(f\"\\t - Recall@{args.k}: {test_recall:3f}\")\n",
    "    print(f\"\\t - MRR@{args.k}: {test_mrr:3f}\\n\")\n",
    "\n",
    "test_model(model, args, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9e065b",
   "metadata": {},
   "source": [
    "### 16-6. 프로젝트 - Movielens 영화 SBR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71cdef4",
   "metadata": {},
   "source": [
    " #### Movielens 1M Dataset을 기반으로, Session based Recommendation 시스템을 제작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9d9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import tensorflow\n",
    "\n",
    "print(pandas.__version__)\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89722b3",
   "metadata": {},
   "source": [
    "1) 데이터 확인\n",
    "$ ls -l ~/data\n",
    "\n",
    "2) 프로젝트 폴더 생성\n",
    "$ mkdir -p ~/aiffel/yoochoose\n",
    "\n",
    "3) 프로젝트 폴더로 데이터 폴더 링크 연결\n",
    "$ ln -s ~/data/* ~/aiffel/yoochoose/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaeb2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(os.getenv('HOME')+'/aiffel/yoochoose/data/') \n",
    "train_path = data_path / 'ratings.dat'\n",
    "\n",
    "def load_data(data_path: Path, nrows=None):\n",
    "    data = pd.read_csv(data_path, sep='::', header=None, usecols=[0, 1, 2, 3], dtype={0: np.int32, 1: np.int32, 2: np.int32}, nrows=nrows)\n",
    "    data.columns = ['UserId', 'ItemId', 'Rating', 'Time']\n",
    "    return data\n",
    "\n",
    "data = load_data(train_path, None)\n",
    "data.sort_values(['UserId', 'Time'], inplace=True)  # data를 id와 시간 순서로 정렬해줍니다.\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b04979",
   "metadata": {},
   "source": [
    " 실습 내역과 가장 크게 다른 부분은 바로 SessionID 대신 UserID 항목이 들어갔다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d454ec",
   "metadata": {},
   "source": [
    "Rating 정보가 포함되어 있다"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfc6919",
   "metadata": {},
   "source": [
    "Time 항목에는 UTC time 가 포함되어, 1970년 1월 1일부터 경과된 초 단위 시간이 기재되어 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09734fcf",
   "metadata": {},
   "source": [
    "### Step 1. 데이터의 전처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8edc74d6",
   "metadata": {},
   "source": [
    "위와 같이 간단히 구성해 본 데이터셋을 꼼꼼히 살펴보면서 항목별 기본 분석, session length, session time, cleaning 등의 작업을 진행합니다.\n",
    "특히, 이 데이터셋에서는 Session이 아닌 UserID 단위로 데이터가 생성되어 있으므로, 이를 Session 단위로 어떻게 해석할지에 주의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64af14e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78f8448",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ab34ea85",
   "metadata": {},
   "source": [
    "### Step 2. 미니 배치의 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5a1f4b",
   "metadata": {},
   "source": [
    "실습 코드 내역을 참고하여 데이터셋과 미니 배치를 구성해 봅시다. Session-Parallel Mini-Batch의 개념에 따라, 학습 속도의 저하가 최소화될 수 있도록 구성합니다.\n",
    "단, 위 Step 1에서 Session 단위를 어떻게 정의했느냐에 따라서 Session-Parallel Mini-Batch이 굳이 필요하지 않을 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b73d97c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ce40d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5825155d",
   "metadata": {},
   "source": [
    "### Step 3. 모델 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161e2b89",
   "metadata": {},
   "source": [
    "이 부분도 실습 코드 내역을 참고하여 다양하게 모델 구조를 시도해 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74ea8f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462746f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "143f813d",
   "metadata": {},
   "source": [
    "### Step 4. 모델 학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052dbc94",
   "metadata": {},
   "source": [
    "다양한 하이퍼파라미터를 변경해 보며 검증해 보도록 합니다. 실습 코드에 언급되었던 Recall, MRR 등의 개념들도 함께 관리될 수 있도록 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d778ec36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16a4483",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cdb25486",
   "metadata": {},
   "source": [
    "### Step 5. 모델 테스트"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8b651",
   "metadata": {},
   "source": [
    "미리 구성한 테스트셋을 바탕으로 Recall, MRR 을 확인해 봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2e96ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13fb709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf0ff7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
